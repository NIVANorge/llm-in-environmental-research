{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:31:27.065713Z",
     "start_time": "2025-06-10T09:31:27.062388Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import anthropic\n",
    "from anthropic import APIError\n",
    "\n",
    "# BILLING: https://www.anthropic.com/pricing#anthropic-api\n",
    "\n",
    "DATASET = 'data/abstracts-500'\n",
    "GET_DOI = False\n",
    "\n",
    "\n",
    "MODEL_VERSION = 'claude-3-5-sonnet-20240620'\n",
    "# MODEL_VERSION = 'claude-3-7-sonnet-20250219'\n",
    "PROMPT = 'v1_prompt'\n",
    "\n",
    "instruction_file = f'./{PROMPT}.txt'\n",
    "dataset_file = f'../{DATASET}.xlsx'\n",
    "output_file = f'./results/claude_2025/{DATASET}_1_output.xlsx'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "878040c7-b85e-4838-ab34-e39e15f4d911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:31:28.536599Z",
     "start_time": "2025-06-10T09:31:28.233087Z"
    }
   },
   "source": [
    "client = anthropic.Anthropic(api_key=\"<API-KEY-HERE>\")\n",
    "\n",
    "df = pd.read_excel(dataset_file)\n",
    "\n",
    "with open(instruction_file, 'r') as file:\n",
    "    instructions = file.read()\n",
    "\n",
    "# Print the instructions that will be fed to Claude\n",
    "print(instructions)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am screening papers for a systematic literature review.\n",
      "The topic of the systematic review is assessing links between urban greenspaces and mental health in low- and middle-income countries. The general urban population of upper/lower-middle-income and low-income countries, as defined by OECDâ€™s Development Assistance Committee (DAC) is included. Studies from high-income countries are excluded.\n",
      "The study should focus exclusively on this topic.\n",
      "\n",
      "Decide if the following article should be included or excluded from the systematic review. I give the title and abstract of the article as input.\n",
      "\n",
      "Please respond with a plain JSON, without any formatting or backticks, that adheres to the following format:\n",
      "{\n",
      "  \"verdict\": \"<your verdict here, either 'include' or 'exclude'>\",\n",
      "  \"explanation\": \"<detailed explanation to justify your verdict here>\",\n",
      "  \"confidence\": \"<confidence level of your decision here>\"\n",
      "}\n",
      "\n",
      "Be lenient. I prefer including papers by mistake rather than excluding them by mistake.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "411b8f5c-b7f9-4ec5-a2f4-72bdc93ddb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:31:29.601167Z",
     "start_time": "2025-06-10T09:31:29.596669Z"
    }
   },
   "source": [
    "def classify_paper(paper: str, retries=5, base_delay=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            message = client.messages.create(\n",
    "                model=MODEL_VERSION,\n",
    "                max_tokens=1024,\n",
    "                temperature=0,\n",
    "                system=instructions,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": paper\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            return message.content[0].text\n",
    "        except APIError as e:\n",
    "            if \"overloaded\" in str(e).lower() and attempt < retries - 1:\n",
    "                delay = base_delay * (2 ** attempt)\n",
    "                print(f\"Server overloaded. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                raise e"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "497b0d0bbb28ce63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:31:30.145441Z",
     "start_time": "2025-06-10T09:31:30.142087Z"
    }
   },
   "source": [
    "def update_output_file(output_file, new_row):\n",
    "\n",
    "    # Define the columns for the DataFrame\n",
    "    columns = [\"ID\", \"Include/exclude\", \"Claude verdict\", \"Claude explanation\", \"Claude confidence\", \"Title\", \"Authors\", \"Abstract\"]\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(output_file):\n",
    "        # Create a new DataFrame with the headers and save it to a new Excel file\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "\n",
    "        # Append the new row to the DataFrame using concat\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        \n",
    "        df.to_excel(output_file, index=False)\n",
    "        print(f\"Created new file: {output_file} and added the first row.\")\n",
    "    else:\n",
    "        # Load the existing file into a DataFrame\n",
    "        df = pd.read_excel(output_file)\n",
    "\n",
    "        # Append the new row to the DataFrame using concat\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "        # Save the updated DataFrame back to the Excel file\n",
    "        df.to_excel(output_file, index=False)\n",
    "        # print(\"New row added to the existing file.\")\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "2f1590d77b487d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T09:31:36.618467Z",
     "start_time": "2025-06-10T09:31:30.834649Z"
    }
   },
   "source": [
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "total_rows_number = len(df)\n",
    "\n",
    "# Iterate over the rows and print the content\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    r = row.to_dict()\n",
    "    paper = f\"Authors: {r['AUTHOR']}\\n\\nTitle: {r['TITLE']}\\n\\nAbstract: {r['ABSTRACT']}\"\n",
    "    # print(f\"Paper ID {r['ID']}: {r['Title']}\\n\")\n",
    "    print(f\"Screening paper {index + 1}/{total_rows_number}\")\n",
    "\n",
    "\n",
    "    # Attempt to classify the paper and handle potential issues\n",
    "    try:\n",
    "        response_content = classify_paper(paper)\n",
    "        # Attempt to parse the JSON response\n",
    "        answer_dict = json.loads(response_content)\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        # print(f\"Failed to decode JSON response for paper ID {r['ID']}: {e}\")\n",
    "        # continue  # Skip this row and move to the next one if JSON parsing fails\n",
    "        # raise RuntimeError(f\"Failed to decode JSON response for paper ID {r['ID']}: {e}\")\n",
    "\n",
    "        new_row = pd.DataFrame([{\n",
    "            \"ID\": r['ID'],\n",
    "            \"Include/exclude\": r['Include/exclude'],\n",
    "            \"Claude verdict\": \"\",\n",
    "            \"Claude explanation\": \"\",\n",
    "            \"Claude confidence\": \"\",\n",
    "            \"Title\": r['TITLE'],\n",
    "            \"Authors\": r['AUTHOR'],\n",
    "            \"Abstract\": r['ABSTRACT']\n",
    "        }])\n",
    "\n",
    "        update_output_file(output_file, new_row)\n",
    "\n",
    "        print(\"ERROR Failed to decode JSON response for paper ID {r['ID']}: {e}\")\n",
    "\n",
    "        continue\n",
    "    \n",
    "    new_row = pd.DataFrame([{\n",
    "        \"ID\": r['ID'],\n",
    "        \"Include/exclude\": r['Include/exclude'],\n",
    "        \"Claude verdict\": answer_dict['verdict'],\n",
    "        \"Claude explanation\": answer_dict['explanation'],\n",
    "        \"Claude confidence\": answer_dict['confidence'],\n",
    "        \"Title\": r['TITLE'],\n",
    "        \"Authors\": r['AUTHOR'],\n",
    "        \"Abstract\": r['ABSTRACT']\n",
    "    }])\n",
    "\n",
    "    update_output_file(output_file, new_row)\n",
    "\n",
    "    if r['Include/exclude'] == answer_dict['verdict'] == \"include\":\n",
    "        true_positives += 1\n",
    "    elif r['Include/exclude'] == answer_dict['verdict'] == \"exclude\":\n",
    "        true_negatives += 1\n",
    "    elif r['Include/exclude'] == \"include\" and answer_dict['verdict'] == \"exclude\":\n",
    "        false_negatives += 1\n",
    "    elif r['Include/exclude'] == \"exclude\" and answer_dict['verdict'] == \"include\":\n",
    "        false_positives += 1\n",
    "        \n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n\\nThis paper screening took {elapsed_time:.1f} seconds\")\n",
    "print(f\"The screening included {true_positives + true_negatives + false_positives + false_negatives} papers, out of which {true_positives + true_negatives} were correctly classified\")\n",
    "print(f\"True positives: {true_positives}\")\n",
    "print(f\"True negatives: {true_negatives}\")\n",
    "print(f\"False positives: {false_positives}\")\n",
    "print(f\"False negatives: {false_negatives}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screening paper 1/1\n",
      "Created new file: ./max/results/claude_2025/correct-abstracts-1_1_output.xlsx and added the first row.\n",
      "ERROR Failed to decode JSON response for paper ID {r['ID']}: {e}\n",
      "\n",
      "\n",
      "This paper screening took 5.8 seconds\n",
      "The screening included 0 papers, out of which 0 were correctly classified\n",
      "True positives: 0\n",
      "True negatives: 0\n",
      "False positives: 0\n",
      "False negatives: 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d317049-9b0e-4b9d-b404-1c9957462f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
