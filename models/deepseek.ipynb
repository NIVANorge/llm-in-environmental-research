{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "\n",
    "DATASET = 'data/abstracts-500'\n",
    "GET_DOI = False\n",
    "\n",
    "MODEL_VERSION = 'deepseek-chat' # DeepSeek-V3\n",
    "\n",
    "PROMPT = 'v1_prompt'\n",
    "\n",
    "instruction_file = f'./{PROMPT}.txt'\n",
    "dataset_file = f'../{DATASET}.xlsx'\n",
    "output_file = f'./results/deepseek_2025/{DATASET}__{PROMPT}__output.xlsx'\n",
    "\n",
    "\n",
    "# https://platform.openai.com/docs/pricing\n",
    "# The unit of the numbers is American Dollars ($)\n",
    "input_tokens_unit_price = 15.00 / 1e6\n",
    "output_tokens_unit_price = 60.00 / 1e6"
   ],
   "id": "80b746f02d7fe7fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "client = OpenAI(api_key='<API-HERE>', base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "df = pd.read_excel(dataset_file)\n",
    "\n",
    "with open(instruction_file, 'r') as file:\n",
    "    instructions = file.read()\n",
    "\n",
    "# Print the instructions that will be fed to ChatGPT\n",
    "print(instructions)"
   ],
   "id": "d75133d0f76ed7a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def clean_json_block(text):\n",
    "    # Remove ```json or ``` or similar at start/end\n",
    "    return re.sub(r\"^```[a-z]*\\s*|\\s*```$\", \"\", text.strip(), flags=re.IGNORECASE)"
   ],
   "id": "ac016c03281a4e50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def classify_paper(paper):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=MODEL_VERSION,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": paper}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    response_content = completion.choices[0].message.content.strip()\n",
    "\n",
    "    # Retrieve the token usage from the response\n",
    "    usage = completion.usage\n",
    "    prompt_tokens = usage.prompt_tokens\n",
    "    completion_tokens = usage.completion_tokens\n",
    "\n",
    "    # Print out token usage details\n",
    "    # print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "    # print(f\"Completion tokens: {completion_tokens}\")\n",
    "\n",
    "    total_cost = prompt_tokens * input_tokens_unit_price + completion_tokens * output_tokens_unit_price\n",
    "\n",
    "    # print(f\"Raw API Response: {response_content}\")\n",
    "\n",
    "    return clean_json_block(response_content), total_cost"
   ],
   "id": "c7ea285b794ee419"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def update_output_file(output_file, new_row):\n",
    "    \n",
    "    columns = new_row.columns\n",
    "\n",
    "    # Define the columns for the DataFrame\n",
    "    # columns = [\"Paper ID\", \"Reviewers verdict\", \"ChatGPT verdict\", \"Reviewer 1\", \"Reviewer 2\", \"Reviewers notes\", \"ChatGPT classification explanation\", \"ChatGPT classification confidence\", \"Title\", \"Authors\", \"Abstract\"]\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(output_file):\n",
    "        # Create a new DataFrame with the headers and save it to a new Excel file\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "\n",
    "        # Append the new row to the DataFrame using concat\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        \n",
    "        df.to_excel(output_file, index=False)\n",
    "        print(f\"Created new file: {output_file} and added the first row.\")\n",
    "    else:\n",
    "        # Load the existing file into a DataFrame\n",
    "        df = pd.read_excel(output_file)\n",
    "\n",
    "        # Append the new row to the DataFrame using concat\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "        # Save the updated DataFrame back to the Excel file\n",
    "        df.to_excel(output_file, index=False)\n",
    "        # print(\"New row added to the existing file.\")"
   ],
   "id": "680b34ca1b602e4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_doi_from_title(title):\n",
    "    url = \"https://api.crossref.org/works\"\n",
    "    params = {\n",
    "        \"query.title\": title,\n",
    "        \"rows\": 1  # Return only the most relevant result\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        items = data.get(\"message\", {}).get(\"items\", [])\n",
    "        \n",
    "        if items:\n",
    "            # Return the DOI of the first matched paper\n",
    "            return items[0].get(\"DOI\", \"null\")\n",
    "        else:\n",
    "            return \"null\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\""
   ],
   "id": "a5228dd9dae50241"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "total_cost = 0\n",
    "\n",
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "total_rows_number = len(df)\n",
    "\n",
    "\n",
    "# Iterate over the rows and print the content\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    r = row.to_dict()\n",
    "    paper = f\"Authors: {r['AUTHOR']}\\n\\nTitle: {r['TITLE']}\\n\\nAbstract: {r['ABSTRACT']}\"\n",
    "    # print(f\"Paper ID {r['ID']}: {r['Title']}\\n\")\n",
    "    print(f\"Screening paper {index + 1}/{total_rows_number}\")\n",
    "\n",
    "    # Attempt to classify the paper and handle potential issues\n",
    "    try:\n",
    "        response_content, cost = classify_paper(paper)\n",
    "        # Attempt to parse the JSON response\n",
    "        print(f\"Response content: {response_content}\")\n",
    "\n",
    "        answer_dict = json.loads(response_content)\n",
    "        total_cost += cost\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        # print(f\"Failed to decode JSON response for paper ID {r['ID']}: {e}\")\n",
    "        # continue  # Skip this row and move to the next one if JSON parsing fails\n",
    "        raise RuntimeError(f\"Failed to decode JSON response for paper ID {r['ID']}: {e}\")\n",
    "    \n",
    "    new_row = pd.DataFrame([{\n",
    "        \"Paper ID\": r['ID'],\n",
    "        \"Reviewers verdict\": r['Include/exclude'],\n",
    "        \"DeepSeek verdict\": answer_dict['verdict'],\n",
    "        \"Verdicts agreement\": \"Y\" if r['Include/exclude'] == answer_dict['verdict'] else \"N\",\n",
    "        \"DeepSeek classification explanation\": answer_dict['explanation'],\n",
    "        \"DeepSeek classification confidence\": answer_dict['confidence'],\n",
    "        \"Title\": r['TITLE'],\n",
    "        \"Authors\": r['AUTHOR'],\n",
    "        \"Abstract\": r['ABSTRACT']\n",
    "    }])\n",
    "\n",
    "    update_output_file(output_file, new_row)\n",
    "\n",
    "    if r['Include/exclude'] == answer_dict['verdict'] == \"include\":\n",
    "        true_positives += 1\n",
    "    elif r['Include/exclude'] == answer_dict['verdict'] == \"exclude\":\n",
    "        true_negatives += 1\n",
    "    elif r['Include/exclude'] == \"include\" and answer_dict['verdict'] == \"exclude\":\n",
    "        false_negatives += 1\n",
    "    elif r['Include/exclude'] == \"exclude\" and answer_dict['verdict'] == \"include\":\n",
    "        false_positives += 1\n",
    "        \n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n\\nThis paper screening took {elapsed_time:.1f} seconds and had a cost of {total_cost:.3f} $\")\n",
    "print(f\"The screening included {true_positives + true_negatives + false_positives + false_negatives} papers, out of which {true_positives + true_negatives} were correctly classified\")\n",
    "print(f\"True positives: {true_positives}\")\n",
    "print(f\"True negatives: {true_negatives}\")\n",
    "print(f\"False positives: {false_positives}\")\n",
    "print(f\"False negatives: {false_negatives}\")\n"
   ],
   "id": "958c4a80b6e0bc8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "900455faa2447c25"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
